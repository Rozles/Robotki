#!/usr/bin/python3

import sys
import math
import rospy
import time
import cv2
import numpy as np
import signal
import tf2_geometry_msgs
import tf2_ros
import re
from os.path import join, dirname
from sensor_msgs.msg import Image
from geometry_msgs.msg import PointStamped, Twist, Vector3
from cv_bridge import CvBridge, CvBridgeError
from visualization_msgs.msg import Marker, MarkerArray
from std_msgs.msg import ColorRGBA 
from trajectory_msgs.msg import JointTrajectory, JointTrajectoryPoint
from std_msgs.msg import String, ColorRGBA
from task3.msg import Poster
from task3.srv import RobberService, RobberServiceResponse
import face_recognition

import pytesseract

class RecognitionNode():
    def __init__(self):

        rospy.init_node('recognition_node', anonymous=True)

        protoPath = join(dirname(__file__), "deploy.prototxt.txt")
        modelPath = join(dirname(__file__), "res10_300x300_ssd_iter_140000.caffemodel")

        self.face_net = cv2.dnn.readNetFromCaffe(protoPath, modelPath)
        self.dims = (0, 0, 0)
       
        
        self.arm_movement_pub = rospy.Publisher('/turtlebot_arm/arm_controller/command', JointTrajectory, queue_size=1)
        self.posters_req = rospy.Subscriber("/poster_req", Image, self.posterCB)
        self.posters_res = rospy.Publisher("/poster_res", Poster, queue_size=10)
        self.robberService = rospy.Service("/robber_service", RobberService, self.robberServiceCB)
        
        self.movement_pub = rospy.Publisher("/cmd_vel_mux/input/teleop", Twist, queue_size=10)

        self.posters = []
        self.encodings = []

        # Pre-defined positions for the arm
        self.retract = JointTrajectory()
        self.retract.joint_names = ["arm_shoulder_pan_joint", "arm_shoulder_lift_joint", "arm_elbow_flex_joint", "arm_wrist_flex_joint"]
        self.retract.points = [JointTrajectoryPoint(positions=[0,-1.3,2.2,1],
                                                    time_from_start = rospy.Duration(1))]

        self.extend = JointTrajectory()
        self.extend.joint_names = ["arm_shoulder_pan_joint", "arm_shoulder_lift_joint", "arm_elbow_flex_joint", "arm_wrist_flex_joint"]
        self.extend.points = [JointTrajectoryPoint(positions=[0,0.3,1,0],
                                                    time_from_start = rospy.Duration(1))]
        
        self.extend2 = JointTrajectory()
        self.extend2.joint_names = ["arm_shoulder_pan_joint", "arm_shoulder_lift_joint", "arm_elbow_flex_joint", "arm_wrist_flex_joint"]
        self.extend2.points = [JointTrajectoryPoint(positions=[0,0.1,0.2,0.5],
                                                    time_from_start = rospy.Duration(1))]
        
        self.right = JointTrajectory()
        self.right.joint_names = ["arm_shoulder_pan_joint", "arm_shoulder_lift_joint", "arm_elbow_flex_joint", "arm_wrist_flex_joint"]
        self.right.points = [JointTrajectoryPoint(positions=[-1.57,0.3,1,0],
                                                    time_from_start = rospy.Duration(1))]
        
        self.bridge = CvBridge()
        self.tf_buf = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buf)

    def stop(self):
        twist = Twist()
        twist.linear.x = 0.0
        twist.linear.z = 0.0
        self.movement_pub.publish(twist)

    def check_text(self, text):
        text = re.sub(r'\W+', '', text)
        color_pattern = r'(BLUE|GREEN|RED|BLACK)'
        number_pattern = r'(\d+)'

        color_match = re.search(color_pattern, text, re.IGNORECASE)
        number_match = re.search(number_pattern, text)

        color = color_match.group(1) if color_match else None
        number = int(number_match.group(1)) if number_match else None
        
        return color, number

    def posterCB(self, img_msg):
        print("RECIEVED")
        try:
            img = self.bridge.imgmsg_to_cv2(img_msg, "bgr8")
        except CvBridgeError as e:
            print(e)
            return
        
        poster = Poster()
        poster.stamp = img_msg.header.stamp
        
        h, w = img.shape[:2]
        img_out = img[h - 100:h-50,10:w-30,:]
        #img_out = cv2.cvtColor(img_out, cv2.COLOR_BGR2GRAY)
        #img_out = cv2.adaptiveThreshold(img_out,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,5)
        #img_out = cv2.bitwise_not(img_out)
        #kernel = np.array([[0,1,0],[1,1,1],[0,1,0]],np.uint8)
        #dilate = cv2.dilate(img_out,kernel,iterations = 1)
        #erode = cv2.erode(dilate,kernel,iterations = 1)
        cv2.imshow("img", img_out)
        cv2.waitKey(0)
        text = pytesseract.image_to_string(img_out, config='--psm 6 --oem 3 -c tessedit_char_whitelist=01')
        color, number = self.check_text(text)
        #print(color, number)
        poster.color = color if color is not None else ""
        poster.reward = number if number is not None else -1
        if (color is not None) and (number is not None):
            face_region = face_recognition.face_locations(img)
            encodings = face_recognition.face_encodings(img, face_region)
            if (len(encodings) == 0):
                poster.encoding = False
                self.posters_res.publish(poster)
                return
            poster.encoding = True
            if (len(self.encodings) > 0):
                distances = face_recognition.face_distance(self.encodings, encodings[0])
                index = np.argmin(distances)
                if (distances[index] < 0.5):
                    print("Nasli smo enak poster")
                    self.posters_res.publish(self.posters[index])
                    return 
            self.encodings.append(encodings[0])
            self.posters.append(poster)
            print("Shranil sem encoding Posterja")
        self.posters_res.publish(poster)
    



    def robberServiceCB(self, data):
        self.arm_movement_pub.publish(self.extend2)
        rospy.sleep(2)
        
        start = rospy.Time.now()
        while(rospy.Time.now() - start).to_sec() < 10:
            try:
                rgb_image_message = rospy.wait_for_message("/arm_camera/rgb/image_raw", Image)
            except Exception as e:
                print(e)
                return 

            try:
                rgb_image = self.bridge.imgmsg_to_cv2(rgb_image_message, "bgr8")
            except CvBridgeError as e:
                print(e)
                return 
            
            face_region = face_recognition.face_locations(rgb_image)
            encodings = face_recognition.face_encodings(rgb_image, face_region)
            print(len(encodings))
            for poster in self.posters:
                try:
                    poster_img = self.bridge.imgmsg_to_cv2(poster.face, "bgr8")
                except CvBridgeError as e:
                    print(e)
                    break
                encodings2 = face_recognition.face_encodings(poster_img)
                if len(encodings2) > 0 and len(encodings) > 2:
                    distance = face_recognition.face_distance(encodings2, encodings[0])
                    if distance < 0.5:
                        self.arm_movement_pub.publish(self.retract)
                        return poster

        self.arm_movement_pub.publish(self.retract)

        return Poster()
    
    def signal_handler(self, signal, frame):
        cv2.destroyAllWindows()
        self.arm_movement_pub.publish(self.retract)
        rospy.signal_shutdown("Keyboard interrupt")


def main():
    rob = RecognitionNode()
    rospy.sleep(0.5)
    rob.arm_movement_pub.publish(rob.retract)

    signal.signal(signal.SIGINT, rob.signal_handler)
    
    r = rospy.Rate(1)
    try:
        while not rospy.is_shutdown():
            r.sleep()
    except rospy.ROSInterruptException:
        pass

    rob.arm_movement_pub.publish(rob.retract)
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
