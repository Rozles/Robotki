#!/usr/bin/python3

import sys
import math
import rospy
import time
import cv2
import numpy as np
import signal
import tf2_geometry_msgs
import tf2_ros
from os.path import join, dirname
from sensor_msgs.msg import Image
from geometry_msgs.msg import PointStamped, Twist, Vector3
from cv_bridge import CvBridge, CvBridgeError
from visualization_msgs.msg import Marker, MarkerArray
from std_msgs.msg import ColorRGBA 
from trajectory_msgs.msg import JointTrajectory, JointTrajectoryPoint
from std_msgs.msg import String, ColorRGBA
from task3.msg import Poster
from task3.srv import RobberService, RobberServiceResponse
        
    

class RobberNode():
    def __init__(self):

        rospy.init_node('robber_node', anonymous=True)

        protoPath = join(dirname(__file__), "deploy.prototxt.txt")
        modelPath = join(dirname(__file__), "res10_300x300_ssd_iter_140000.caffemodel")

        self.face_net = cv2.dnn.readNetFromCaffe(protoPath, modelPath)
        self.dims = (0, 0, 0)
       
        
        self.arm_movement_pub = rospy.Publisher('/turtlebot_arm/arm_controller/command', JointTrajectory, queue_size=1)
        self.start = rospy.Subscriber("/posters", Poster, self.posterCB)
        self.robberService = rospy.Service("/robber_service", RobberService, self.robberServiceCB)
        
        self.movement_pub = rospy.Publisher("/cmd_vel_mux/input/teleop", Twist, queue_size=10)

        self.posters = []

        # Pre-defined positions for the arm
        self.retract = JointTrajectory()
        self.retract.joint_names = ["arm_shoulder_pan_joint", "arm_shoulder_lift_joint", "arm_elbow_flex_joint", "arm_wrist_flex_joint"]
        self.retract.points = [JointTrajectoryPoint(positions=[0,-1.3,2.2,1],
                                                    time_from_start = rospy.Duration(1))]

        self.extend = JointTrajectory()
        self.extend.joint_names = ["arm_shoulder_pan_joint", "arm_shoulder_lift_joint", "arm_elbow_flex_joint", "arm_wrist_flex_joint"]
        self.extend.points = [JointTrajectoryPoint(positions=[0,0.3,1,0],
                                                    time_from_start = rospy.Duration(1))]
        
        self.extend2 = JointTrajectory()
        self.extend2.joint_names = ["arm_shoulder_pan_joint", "arm_shoulder_lift_joint", "arm_elbow_flex_joint", "arm_wrist_flex_joint"]
        self.extend2.points = [JointTrajectoryPoint(positions=[0,0.1,0.2,0.5],
                                                    time_from_start = rospy.Duration(1))]
        
        self.right = JointTrajectory()
        self.right.joint_names = ["arm_shoulder_pan_joint", "arm_shoulder_lift_joint", "arm_elbow_flex_joint", "arm_wrist_flex_joint"]
        self.right.points = [JointTrajectoryPoint(positions=[-1.57,0.3,1,0],
                                                    time_from_start = rospy.Duration(1))]
        
        self.bridge = CvBridge()
        self.tf_buf = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buf)

    def stop(self):
        twist = Twist()
        twist.linear.x = 0.0
        twist.linear.z = 0.0
        self.movement_pub.publish(twist)

    def posterCB(self, data):
        self.posters.append(data)

    def robberServiceCB(self, data):
        self.arm_movement_pub.publish(self.extend2)

        rospy.sleep(2)
        while True:
            try:
                rgb_image_message = rospy.wait_for_message("/arm_camera/rgb/image_raw", Image)
            except Exception as e:
                print(e)
                return 

            try:
                rgb_image = self.bridge.imgmsg_to_cv2(rgb_image_message, "bgr8")
            except CvBridgeError as e:
                print(e)
                return 
            
            self.dims = rgb_image.shape
            h = self.dims[0]
            w = self.dims[1]
            
            blob = cv2.dnn.blobFromImage(cv2.resize(rgb_image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))
            
            self.face_net.setInput(blob)
            face_detections = self.face_net.forward()

            for i in range(0, face_detections.shape[2]):
                confidence = face_detections[0, 0, i, 2]
                if confidence>0.5:
                    box = face_detections[0,0,i,3:7] * np.array([w,h,w,h])
                    box = box.astype('int')
                    x1, y1, x2, y2 = box[0], box[1], box[2], box[3]

                    # Extract region containing face
                    face_region = rgb_image[y1:y2, x1:x2]
                    cv2.imshow("face", face_region)
                    cv2.waitKey(1)

        

        self.arm_movement_pub.publish(self.retract)

        return Poster()
    
    def signal_handler(self, signal, frame):
        cv2.destroyAllWindows()
        self.arm_movement_pub.publish(self.retract)
        rospy.signal_shutdown("Keyboard interrupt")
        

        
        



def main():
    rob = RobberNode()
    rospy.sleep(0.5)
    rob.arm_movement_pub.publish(rob.retract)

    signal.signal(signal.SIGINT, rob.signal_handler)
    
    r = rospy.Rate(1)
    try:
        while not rospy.is_shutdown():
            r.sleep()
    except rospy.ROSInterruptException:
        pass

    rob.arm_movement_pub.publish(rob.retract)
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
